import pyodbc
import pandas as pd

# Establish connection to Hive using pyodbc
conn = pyodbc.connect('DSN=YourHiveDSN', autocommit=True)

# Example: Original table name and filtered DataFrame
original_table_name = "your_original_table_name"
filtered_df = pd.DataFrame(...)  # Your filtered DataFrame

# SQL query to fetch the original table schema
schema_query = f"DESCRIBE {original_table_name}"

# Execute the schema query using pyodbc cursor
cursor = conn.cursor()
cursor.execute(schema_query)

# Fetch column descriptions
columns = [column[0] for column in cursor.fetchall()]

# Close the cursor
cursor.close()

# Create a temporary table in Hive (using the original table's structure)
create_temp_table_query = f"CREATE TABLE temp_table_name LIKE {original_table_name}"
cursor = conn.cursor()
cursor.execute(create_temp_table_query)
cursor.close()

# Insert data from filtered DataFrame into the temporary table
cursor = conn.cursor()
for index, row in filtered_df.iterrows():
    # Example: Using parameterized query with ? placeholders
    insert_query = f"INSERT INTO temp_table_name ({', '.join(columns)}) VALUES ({', '.join(['?'] * len(columns))})"
    cursor.execute(insert_query, tuple(row))
cursor.close()

# Optionally, create a permanent table based on the temporary table
create_permanent_table_query = f"CREATE TABLE new_table_name AS SELECT * FROM temp_table_name"
cursor = conn.cursor()
cursor.execute(create_permanent_table_query)
cursor.close()

# Close the connection
conn.close()